"""
Camera AI - H·ªá th·ªëng ph√°t hi·ªán ng∆∞·ªùi v√† xe v·ªõi YOLOv11
"""
import cv2
import yaml
import torch
from datetime import datetime
import os
import sqlite3
import numpy as np
from pathlib import Path
from ultralytics import YOLO

# Ch·ªçn detector d·ª±a tr√™n config
try:
    with open('config.yaml', 'r', encoding='utf-8') as f:
        _config = yaml.safe_load(f)
    
    if _config.get('license_plate', {}).get('use_yolo', False):
        from license_plate_yolo import YOLOLicensePlateDetector as LicensePlateDetector
        print("üéØ S·ª≠ d·ª•ng YOLO License Plate Detector")
    else:
        from license_plate import LicensePlateDetector
        print("üìù S·ª≠ d·ª•ng Contour License Plate Detector")
except Exception as e:
    from license_plate import LicensePlateDetector
    print(f"‚ö†Ô∏è  L·ªói khi load config, d√πng detector m·∫∑c ƒë·ªãnh: {e}")

# Import FFMPEG camera n·∫øu l√† RTSP
try:
    from ffmpeg_camera import FFMPEGCamera
    FFMPEG_AVAILABLE = True
except ImportError:
    FFMPEG_AVAILABLE = False
    print("‚ö†Ô∏è  FFMPEG camera module kh√¥ng c√≥, s·∫Ω d√πng OpenCV")

class CameraAI:
    def __init__(self, config_path='config.yaml'):
        """Kh·ªüi t·∫°o Camera AI System"""
        # Load config
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        print("üöÄ ƒêang kh·ªüi ƒë·ªông Camera AI System...")
        
        # Kh·ªüi t·∫°o models
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"üì± S·ª≠ d·ª•ng device: {self.device}")
        
        # Load YOLO models
        model_path = self.config['detection']['person_model']
        if not os.path.exists(model_path):
            print(f"‚¨áÔ∏è  ƒêang t·∫£i YOLOv11 model...")
            self.model = YOLO('yolo11n.pt')  # T·ª± ƒë·ªông download
            os.makedirs('models', exist_ok=True)
            # Model s·∫Ω ƒë∆∞·ª£c t·∫£i t·ª± ƒë·ªông
        else:
            self.model = YOLO(model_path)
        
        # Kh·ªüi t·∫°o License Plate Detector
        self.plate_detector = LicensePlateDetector(self.config)
        
        # Kh·ªüi t·∫°o camera
        self.cap = None
        self.setup_camera()
        
        # Kh·ªüi t·∫°o database
        self.setup_database()
        
        # Recording settings
        self.video_writer = None
        self.current_video_path = None
        
        # Th·ªëng k√™
        self.stats = {
            'total_persons': 0,
            'total_vehicles': 0,
            'total_plates': 0,
            'last_detection': None
        }
        
        print("‚úÖ Camera AI System ƒë√£ s·∫µn s√†ng!")
    
    def setup_camera(self):
        """Thi·∫øt l·∫≠p k·∫øt n·ªëi camera"""
        source = self.config['camera']['source']
        
        # Ki·ªÉm tra n·∫øu l√† RTSP URL
        is_rtsp = isinstance(source, str) and source.startswith('rtsp://')
        
        if is_rtsp and FFMPEG_AVAILABLE:
            # D√πng FFMPEG camera cho RTSP (ho·∫°t ƒë·ªông t·ªët h∆°n tr√™n macOS)
            print(f"üì° Ph√°t hi·ªán RTSP stream, d√πng FFMPEG backend...")
            self.cap = FFMPEGCamera(
                source,
                width=self.config['camera']['width'],
                height=self.config['camera']['height'],
                fps=self.config['camera']['fps']
            )
            
            if not self.cap.start():
                raise Exception(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi RTSP stream: {source}")
        else:
            # D√πng OpenCV cho webcam ho·∫∑c RTSP (n·∫øu FFMPEG kh√¥ng c√≥)
            if is_rtsp:
                # D√πng FFMPEG backend cho RTSP
                self.cap = cv2.VideoCapture(source, cv2.CAP_FFMPEG)
                
                # Set buffer size n·∫øu c√≥ trong config (gi·∫£m ƒë·ªô tr·ªÖ)
                if 'buffer_size' in self.config['camera']:
                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, self.config['camera']['buffer_size'])
                    print(f"üì¶ Buffer size: {self.config['camera']['buffer_size']}")
            else:
                self.cap = cv2.VideoCapture(source)
            
            if not self.cap.isOpened():
                if is_rtsp:
                    print(f"‚ö†Ô∏è  OpenCV kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c RTSP, th·ª≠ c√†i FFMPEG camera module")
                raise Exception(f"‚ùå Kh√¥ng th·ªÉ m·ªü camera: {source}")
            
            # Set resolution
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.config['camera']['width'])
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.config['camera']['height'])
            self.cap.set(cv2.CAP_PROP_FPS, self.config['camera']['fps'])
        
        print(f"üìπ Camera ƒë√£ k·∫øt n·ªëi: {source}")
    
    def setup_database(self):
        """T·∫°o database ƒë·ªÉ l∆∞u log"""
        db_path = self.config['database']['path']
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # B·∫£ng detections
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS detections (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                type TEXT,
                confidence REAL,
                bbox TEXT,
                snapshot_path TEXT,
                license_plate TEXT,
                vehicle_type TEXT,
                notes TEXT
            )
        ''')
        
        # Migration: Th√™m c·ªôt vehicle_type n·∫øu ch∆∞a c√≥
        try:
            cursor.execute("SELECT vehicle_type FROM detections LIMIT 1")
        except sqlite3.OperationalError:
            print("üîß ƒêang migrate database: th√™m c·ªôt vehicle_type...")
            cursor.execute("ALTER TABLE detections ADD COLUMN vehicle_type TEXT")
            conn.commit()
            print("‚úÖ Migration ho√†n t·∫•t!")
        
        # B·∫£ng statistics
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date DATE,
                total_persons INTEGER,
                total_vehicles INTEGER,
                total_plates INTEGER
            )
        ''')
        
        conn.commit()
        conn.close()
        print("üíæ Database ƒë√£ s·∫µn s√†ng")
    
    def start_recording(self):
        """B·∫Øt ƒë·∫ßu ghi video"""
        if not self.config['recording']['enabled']:
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.current_video_path = os.path.join(
            self.config['recording']['save_path'],
            f"recording_{timestamp}.mp4"
        )
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = self.config['camera']['fps']
        size = (self.config['camera']['width'], self.config['camera']['height'])
        
        self.video_writer = cv2.VideoWriter(
            self.current_video_path, fourcc, fps, size
        )
        print(f"üé• B·∫Øt ƒë·∫ßu ghi: {self.current_video_path}")
    
    def save_snapshot(self, frame, detection_type, extra_info=""):
        """L∆∞u ·∫£nh snapshot"""
        if not self.config['recording']['save_snapshots']:
            return None
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        filename = f"{detection_type}_{timestamp}.jpg"
        filepath = os.path.join(
            self.config['recording']['snapshot_path'],
            filename
        )
        
        cv2.imwrite(filepath, frame)
        return filepath
    
    def get_vehicle_type(self, class_id):
        """Ph√¢n lo·∫°i xe d·ª±a tr√™n YOLO class ID"""
        # COCO dataset classes:
        # 1: bicycle, 2: car, 3: motorcycle, 5: bus, 7: truck
        vehicle_types = {
            1: 'Xe ƒë·∫°p',
            2: '√î t√¥',
            3: 'Xe m√°y',
            5: 'Xe bu√Ωt',
            7: 'Xe t·∫£i'
        }
        return vehicle_types.get(class_id, 'Xe kh√°c')
    
    def log_detection(self, det_type, confidence, bbox, snapshot_path=None, plate=None, vehicle_type=None):
        """Ghi log v√†o database"""
        conn = sqlite3.connect(self.config['database']['path'])
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO detections (type, vehicle_type, confidence, bbox, snapshot_path, license_plate)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (det_type, vehicle_type, confidence, str(bbox), snapshot_path, plate))
        
        conn.commit()
        conn.close()
    
    def detect_frame(self, frame):
        """Ph√°t hi·ªán objects trong frame"""
        results = self.model(frame, verbose=False)
        
        detections = {
            'persons': [],
            'vehicles': [],
            'plates': []
        }
        
        for result in results:
            boxes = result.boxes
            for box in boxes:
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                bbox = box.xyxy[0].cpu().numpy()
                
                # Ph√°t hi·ªán ng∆∞·ªùi
                if cls in self.config['detection']['person_classes']:
                    if conf >= self.config['detection']['person_confidence']:
                        detections['persons'].append({
                            'bbox': bbox,
                            'confidence': conf
                        })
                        self.stats['total_persons'] += 1
                
                # Ph√°t hi·ªán xe
                elif cls in self.config['detection']['vehicle_classes']:
                    if conf >= self.config['detection']['vehicle_confidence']:
                        vehicle_type = self.get_vehicle_type(cls)
                        detections['vehicles'].append({
                            'bbox': bbox,
                            'confidence': conf,
                            'class': cls,
                            'vehicle_type': vehicle_type
                        })
                        self.stats['total_vehicles'] += 1
                        
                        # Crop v√πng xe ƒë·ªÉ ph√°t hi·ªán bi·ªÉn s·ªë (m·ªü r·ªông th√™m 10% ƒë·ªÉ bao g·ªìm bi·ªÉn s·ªë)
                        x1, y1, x2, y2 = map(int, bbox)
                        h_frame, w_frame = frame.shape[:2]
                        
                        # M·ªü r·ªông v√πng crop
                        expand_ratio = 0.1
                        w_box = x2 - x1
                        h_box = y2 - y1
                        x1_exp = max(0, int(x1 - w_box * expand_ratio))
                        y1_exp = max(0, int(y1 - h_box * expand_ratio))
                        x2_exp = min(w_frame, int(x2 + w_box * expand_ratio))
                        y2_exp = min(h_frame, int(y2 + h_box * expand_ratio))
                        
                        vehicle_crop = frame[y1_exp:y2_exp, x1_exp:x2_exp]
                        
                        # Ph√°t hi·ªán bi·ªÉn s·ªë
                        plate_result = self.plate_detector.detect(vehicle_crop)
                        if plate_result:
                            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô bi·ªÉn s·ªë t·ª´ vehicle_crop sang frame g·ªëc
                            plate_bbox_in_frame = None
                            if plate_result.get('bbox'):
                                px, py, pw, ph = plate_result['bbox']
                                # T·ªça ƒë·ªô trong frame g·ªëc
                                plate_x1 = x1_exp + px
                                plate_y1 = y1_exp + py
                                plate_x2 = plate_x1 + pw
                                plate_y2 = plate_y1 + ph
                                plate_bbox_in_frame = (plate_x1, plate_y1, plate_x2, plate_y2)
                            
                            detections['plates'].append({
                                'vehicle_bbox': bbox,
                                'plate_bbox': plate_bbox_in_frame,  # T·ªça ƒë·ªô bi·ªÉn s·ªë trong frame
                                'plate_text': plate_result['text'],
                                'plate_confidence': plate_result['confidence']
                            })
                            self.stats['total_plates'] += 1
                            print(f"   ‚úÖ Ph√°t hi·ªán bi·ªÉn s·ªë: {plate_result['text']} ({vehicle_type})")
        
        self.stats['last_detection'] = datetime.now()
        return detections
    
    def draw_detections(self, frame, detections):
        """V·∫Ω bounding boxes l√™n frame"""
        # V·∫Ω ng∆∞·ªùi
        for person in detections['persons']:
            x1, y1, x2, y2 = map(int, person['bbox'])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"Person: {person['confidence']:.2f}"
            cv2.putText(frame, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # V·∫Ω xe
        for vehicle in detections['vehicles']:
            x1, y1, x2, y2 = map(int, vehicle['bbox'])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
            
            # Hi·ªÉn th·ªã lo·∫°i xe v√† confidence
            vehicle_type = vehicle.get('vehicle_type', 'Xe')
            label = f"{vehicle_type}: {vehicle['confidence']:.2f}"
            
            # V·∫Ω n·ªÅn cho text
            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, (x1, y1-text_h-10), (x1+text_w, y1), (255, 0, 0), -1)
            cv2.putText(frame, label, (x1, y1-5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # V·∫Ω bi·ªÉn s·ªë
        for plate in detections['plates']:
            # V·∫Ω khung v√†ng quanh bi·ªÉn s·ªë (n·∫øu c√≥ t·ªça ƒë·ªô)
            if plate.get('plate_bbox'):
                px1, py1, px2, py2 = map(int, plate['plate_bbox'])
                # Khung v√†ng n·ªïi b·∫≠t cho bi·ªÉn s·ªë
                cv2.rectangle(frame, (px1, py1), (px2, py2), (0, 255, 255), 3)
                
                # V·∫Ω n·ªÅn cho text bi·ªÉn s·ªë
                text = plate['plate_text']
                font_scale = 0.8
                thickness = 2
                (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
                
                # N·ªÅn ƒëen cho text
                cv2.rectangle(frame, (px1, py1-text_h-10), (px1+text_w+10, py1), (0, 0, 0), -1)
                # Text v√†ng
                cv2.putText(frame, text, (px1+5, py1-5),
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), thickness)
            else:
                # N·∫øu kh√¥ng c√≥ bbox bi·ªÉn s·ªë, v·∫Ω text d∆∞·ªõi xe
                x1, y1, x2, y2 = map(int, plate['vehicle_bbox'])
                text = f"Plate: {plate['plate_text']}"
                cv2.putText(frame, text, (x1, y2+20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # Th√™m th·ªëng k√™
        stats_text = f"Persons: {len(detections['persons'])} | Vehicles: {len(detections['vehicles'])} | Plates: {len(detections['plates'])}"
        cv2.putText(frame, stats_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame
    
    def run(self, show_preview=True):
        """Ch·∫°y h·ªá th·ªëng detection"""
        print("‚ñ∂Ô∏è  B·∫Øt ƒë·∫ßu ph√°t hi·ªán...")
        self.start_recording()
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ö†Ô∏è  Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame")
                    break
                
                # Ph√°t hi·ªán objects
                detections = self.detect_frame(frame)
                
                # V·∫Ω k·∫øt qu·∫£
                frame_display = self.draw_detections(frame.copy(), detections)
                
                # Ghi video
                if self.video_writer:
                    self.video_writer.write(frame_display)
                
                # L∆∞u snapshots n·∫øu c√≥ detection
                if detections['persons'] or detections['vehicles']:
                    if self.config['recording']['save_snapshots']:
                        snapshot_path = self.save_snapshot(
                            frame_display, 
                            'detection'
                        )
                        
                        # Log v√†o database
                        for person in detections['persons']:
                            self.log_detection(
                                'person',
                                person['confidence'],
                                person['bbox'],
                                snapshot_path
                            )
                        
                        for vehicle in detections['vehicles']:
                            plate_text = None
                            # T√¨m bi·ªÉn s·ªë t∆∞∆°ng ·ª©ng
                            for plate in detections['plates']:
                                if np.array_equal(plate['vehicle_bbox'], vehicle['bbox']):
                                    plate_text = plate['plate_text']
                                    break
                            
                            self.log_detection(
                                'vehicle',
                                vehicle['confidence'],
                                vehicle['bbox'],
                                snapshot_path,
                                plate_text
                            )
                
                # Hi·ªÉn th·ªã preview
                if show_preview:
                    cv2.imshow('Camera AI - Press Q to quit', frame_display)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  D·ª´ng h·ªá th·ªëng...")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """D·ªçn d·∫πp t√†i nguy√™n"""
        if self.cap:
            if hasattr(self.cap, 'release'):
                self.cap.release()
        if self.video_writer:
            self.video_writer.release()
        cv2.destroyAllWindows()
        print("üßπ ƒê√£ d·ªçn d·∫πp t√†i nguy√™n")
    
    def get_stats(self):
        """L·∫•y th·ªëng k√™"""
        return self.stats

if __name__ == '__main__':
    # Ch·∫°y camera AI
    camera = CameraAI()
    camera.run(show_preview=True)

